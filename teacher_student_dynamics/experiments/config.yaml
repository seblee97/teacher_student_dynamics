seed: 0
gpu_id: 0 # None for CPU

runner:
    run_ode: True
    run_network: True

logging:
    checkpoint_frequency: 10000
    stdout_frequency: 10000

    overlap_frequency: 10000 # save in standard logging format
    save_overlap_frequency: 1000 # save into ode-readable format (for debugging) ensure this is multiple of input_dimension * timestep
    ode_log_frequency: 1000 # ensure this is multiple of input_dimension * timestep

ode:
    implementation: cpp
    omp: False
    omp_num_threads: 0
    eigen_path: 
    timestep: 0.001

    debug_copy: []
        # - "W" # think this works
        # - "r_density"
        # - "u_density"
        # - "sigma_1_density"
        # - "sigma_2_density"
        # - "Sigma1"
        # - "Sigma2"
        # - "Q"
        # - "R"
        # - "U"
        # - "h1"
        # - "h2"

data:
    input_source: hidden_manifold # iid_gaussian, hidden_manifold

    precompute_data: 1000

    iid_gaussian:
        mean: 0
        variance: 1
        dataset_size: inf

    hidden_manifold:
        mean: 0
        variance: 1
        latent_dimension: 100
        activation: sign # scaled_erf or sign

        # number of bins for discretising densities
        num_bins: 1000

        feature_matrix_correlations: [1.]

    noise_to_student_input:
    # list of lists dim 2 (one per teacher)
    # each specifies mean, variance
    # empty for no noise
    - []
    - []

    noise_to_teacher_output: 
    # list of lists dim 2 (one per teacher)
    # each specifies mean, variance
    # empty for no noise
    - []
    - []

testing:
    test_batch_size: 10000
    test_frequency: 10000

training:
    train_batch_size: 1
    total_training_steps: 100000000
    optimiser: sgd
    learning_rate: 0.2
    loss_function: mse
    train_hidden_layer: True
    train_head_layer: True
    copy_head_at_switch: False
    
    # list of dim num_teachers. 
    # Each item is number of units to freeze for each teacher.
    freeze_units: [0, 0]

networks:
    input_dimension: 10000
    output_dimension: 1
    nonlinearity: scaled_erf
    # student
    student_hidden: 2
    student_bias: False
    student_initialisation_std: 0.001
    multi_head: False
    # teacher(s)
    num_teachers: 2
    teacher_hidden: 2
    teacher_bias: False
    teacher_heads_one: False # make all teacher head weights 1 (like fig. 3 of HMM paper)
    unit_norm_teacher_head: True
    normalise_teachers: True
    teacher_initialisation_std: 1.
    teacher_configuration: identical # rotation, identical, node_sharing

    rotation_teachers:
        feature_rotation_alpha: 0.
        readout_rotation_alpha: 0.

    node_sharing_teachers:
        num_shared_nodes: 1
        feature_rotation_alpha: 0.

curriculum:
    # condition on which to switch task (fixed_period, switch_steps, or loss_thresholds)
    stopping_condition: switch_steps              
  
    switch_steps: [1500000000]
    fixed_period: 1
    # loss threshold under which teacher is changed
    loss_thresholds: [0.0001]

replay:
    schedule:  # periodic or None for no replay

    strategy: gamma # uniform or gamma (hmm)
    
    periodic_replay:
        # how often to interleave previous examples
        interleave_period: 100
        # number of examples from previous task to show in each interleaving                                      
        interleave_duration: 1

    gamma_replay:
        gamma: 0.5
    