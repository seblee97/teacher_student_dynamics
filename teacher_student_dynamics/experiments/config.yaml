seed: 0
gpu_id: 0 # None for CPU

runner:
    run_ode: False
    run_network: True

logging:
    checkpoint_frequency: 10000
    stdout_frequency: 10000

    overlap_frequency: 10000 # save in standard logging format
    save_overlap_frequency: 1000 # save into ode-readable format (for debugging) ensure this is multiple of input_dimension * timestep
    ode_log_frequency: 1000 # ensure this is multiple of input_dimension * timestep

    debug_copy: []

ode:
    implementation: cpp
    omp: False
    omp_num_threads: 0
    eigen_path: 
    timestep: 0.001

data:
    input_source: hidden_manifold # iid_gaussian, hidden_manifold

    precompute_data: 1000

    iid_gaussian:
        mean: 0
        variance: 1
        dataset_size: inf

    hidden_manifold:
        mean: 0
        variance: 1
        latent_dimension: 140 #100
        activation: sign # scaled_erf or sign

        construction: domine_ssm # goldt or domine_ssm

        feature_matrix_correlations: [0.6,0.4] #[0.6]

    noise_to_student_input:
    # list of lists dim 2 (one per teacher)
    # each specifies mean, variance
    # empty for no noise
    - []
    - []

    noise_to_teacher_output: 
    # list of lists dim 2 (one per teacher)
    # each specifies mean, variance
    # empty for no noise
    - []
    - []

testing:
    test_batch_size: 10000
    test_frequency: 10000

training:
    train_batch_size: 1
    total_training_steps: 10000000 #1000000 #100000000
    optimiser: sgd
    learning_rate: 0.2
    loss_function: mse
    train_hidden_layer: True
    train_head_layer: True
    copy_head_at_switch: False
    
    # list of dim num_teachers. 
    # Each item is number of units to freeze for each teacher.
    freeze_units: [0, 0]

networks:
    input_dimension: 10000
    output_dimension: 1
    nonlinearity: scaled_erf
    # student
    student_hidden: 4
    student_bias: False
    student_initialisation_std: 0.001
    multi_head: False
    # teacher(s)
    num_teachers: 2
    teacher_hidden: 2
    teacher_bias: False
    teacher_heads_one: False # make all teacher head weights 1 (like fig. 3 of HMM paper)
    unit_norm_teacher_head: True
    normalise_teachers: True
    teacher_initialisation_std: 1.
    teacher_configuration: identical # rotation, identical, node_sharing

    rotation_teachers:
        feature_rotation_alpha: 0.
        readout_rotation_alpha: 0.

    node_sharing_teachers:
        num_shared_nodes: 1
        feature_rotation_alpha: 0.

curriculum:
    # condition on which to switch task (fixed_period, switch_steps, or loss_thresholds)
    stopping_condition: switch_steps              
  
    switch_steps: [5000000] #[500000] #[1500000000]
    fixed_period: 1
    # loss threshold under which teacher is changed
    loss_thresholds: [0.0001]

replay:
    schedule:  # periodic or None for no replay

    strategy: gamma # uniform or gamma (hmm)
    
    periodic_replay:
        # how often to interleave previous examples
        interleave_period: 100
        # number of examples from previous task to show in each interleaving                                      
        interleave_duration: 1

    gamma_replay:
        gamma: 0.5
    
